---
title: "Foundations for statistical inference - Sampling distributions"
output:
  html_document:
    css: ../lab.css
    highlight: pygments
    theme: cerulean
  pdf_document: default
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
library(dplyr)
library(ggplot2)
library(mosaic)
```

In this lab, we investigate the ways in which the statistics from a random 
sample of data can serve as point estimates for population parameters. We're 
interested in formulating a *sampling distribution* of our estimate in order 
to learn about the properties of the estimate, such as its distribution.

## The data

We consider real estate data from the city of Ames, Iowa. The details of 
every real estate transaction in Ames is recorded by the City Assessor's 
office. Our particular focus for this lab will be all residential home sales 
in Ames between 2006 and 2010.  This collection represents our population of 
interest. In this lab we would like to learn about these home sales by taking 
smaller samples from the full population. Let's load the data.

```{r load-data}
load(url("https://stat.duke.edu/~mc301/data/ames.RData")) # will need to be updated
```

We see that there are quite a few variables in the data set, enough to do a 
very in-depth analysis. For this lab, we'll restrict our attention to just 
two of the variables: the above ground living area of the house in square feet 
(`area`) and the sale price (`price`).

We can explore the distribution of areas of homes in the population of home
sales visually and with summary statistics. Let's first create a visualization,
a histogram:

```{r area-hist}
qplot(data = ames, x = area, binwidth = 250)
```

Let's also obtain some summary statistics. Note that we can do this using the
`summarise` function. We can calculate as many statistics as we want using this
function, and just string along the results. Some of the functions below should
be self explanatory (like `mean`, `median`, `sd`, `IQR`, `min`, and `max`). A
new function here is the `quantile` function which we can use to calculate 
values corresponding to specific percentile cutoffs in the distribution. For
example `quantile(x, 0.25)` will yield the cutoff value for the 25th percentile (Q1)
in the distribution of x. Finding these values are useful for describing the 
distribution, as we can use them for descriptions like *"the middle 50% of the 
homes have areas between such and such square feet"*.

```{r area-stats}
ames %>%
  summarise(mu = mean(area), pop_med = median(area), 
            sigma = sd(area), pop_iqr = IQR(area),
            pop_min = min(area), pop_max = max(area),
            pop_q1 = quantile(area, 0.25),  # first quartile, 25th percentile
            pop_q3 = quantile(area, 0.75))  # third quartile, 75th percentile
```

1.  Describe this population distribution using the visualization and the summary
    statistics. You don't have to use all of the summary statistics in your 
    description, you will need to decide which ones are relevant based on the
    shape of the distribution. Make sure to include the plot and the summary
    statistics output in your report along with your narrative.

## The unknown sampling distribution

In this lab we have access to the entire population, but this is rarely the 
case in real life. Gathering information on an entire population is often 
extremely costly or impossible. Because of this, we often take a sample of 
the population and use that to understand the properties of the population.

If we were interested in estimating the mean living area in Ames based on a 
sample, we can use the following command to survey the population.

```{r samp1}
samp1 <- ames %>%
  sample_n(50)
```

The `sample_n` function collects a simple random sample of size 50 from the `ames` dataset 
`area`, which is assigned to `samp1`. This is like going into the City 
Assessor's database and pulling up the files on 50 random home sales. Working 
with these 50 files would be considerably simpler than working with all 2930 
home sales.

1.  Describe the distribution of area in this sample. How does it compare to the 
    distribution of the population? **Hint:** `sample_n` function takes a random
    sample of observations (i.e. rows) from the dataset, you can still refer to 
    the variables in the dataset with the same names. Code you used in the 
    previous exercise will also be helpful for visualizing and summarizing the sample,
    however be careful to not label values `mu` and `sigma` anymore since these
    are sample statistics, not population parameters. You can customize the labels
    of any of the statistics to indicate that these come from the sample.

If we're interested in estimating the average living area in homes in Ames 
using the sample, our best single guess is the sample mean.

```{r mean-samp1}
samp1 %>%
  summarise(x_bar = mean(area))
```

Depending on which 50 homes you selected, your estimate could be a bit above 
or a bit below the true population mean of 1499.69 square feet. In general, 
though, the sample mean turns out to be a pretty good estimate of the average 
living area, and we were able to get it by sampling less than 3\% of the 
population.

1.  Take a second sample, also of size 50, and call it `samp2`. How does the 
    mean of `samp2` compare with the mean of `samp1`? Suppose we took two 
    more samples, one of size 100 and one of size 1000. Which would you think 
    would provide a more accurate estimate of the population mean?

Not surprisingly, every time we take another random sample, we get a different 
sample mean. It's useful to get a sense of just how much variability we 
should expect when estimating the population mean this way. The distribution 
of sample means, called the *sampling distribution*, can help us understand 
this variability. In this lab, because we have access to the population, we 
can build up the sampling distribution for the sample mean by repeating the 
above steps many times. Here we will generate 2000 samples and compute the 
sample mean of each. Note that we are sampling with replacement. Thus, we set 
`replace = TRUE`.

```{r loop}
sample_means50 <- do(2000) * ames %>% 
                              sample_n(50, replace = TRUE) %>%
                              summarise(x_bar = mean(area))
                          
qplot(data = sample_means50, x = x_bar)
```

Here we use R to take 2000 samples of size 50 from the population, calculate 
the mean of each sample, and store each result in a vector called 
`sample_means50`. On the next page, we'll review how this set of code works.

1.  How many elements are there in `sample_means50`?  Describe the sampling 
    distribution, and be sure to specifically note its center. Would you 
    expect the distribution to change if we instead collected 10,000 sample 
    means?

## Interlude: The `do` function

Let's take a break from the statistics for a moment to let that last block 
of code sink in. The idea behind the `do` function is *repetition*: it allows 
you to execute a line of code as many times as you want and put the results 
in a data frame.  In the case above, we wanted to repeatedly take a random 
sample of size 50 from `area` and then save the mean of that sample into 
the `sample_means50` vector.

Without the `do` function, this would be painful. First, we'd have to create 
an empty vector filled with `NA`s to hold the 2000 sample means. Then, we'd have 
to compute each of the 2000 sample means one line at a time, putting them 
individually into the slots of the `sample_means50` vector:

```{r do-long}
sample_means50 <- rep(NA, 2000)

sample_means50[1] <-  ames %>%
                        sample_n(50, replace = TRUE) %>%
                        summarise(x_bar = mean(area))
sample_means50[2] <- ames %>%
                        sample_n(50, replace = TRUE) %>%
                        summarise(x_bar = mean(area))
sample_means50[3] <- ames %>%
                        sample_n(50, replace = TRUE) %>%
                        summarise(x_bar = mean(area))
sample_means50[4] <- ames %>%
                        sample_n(50, replace = TRUE) %>%
                        summarise(x_bar = mean(area))
# ...and so on, 2000 times
```

With the `do` function, these thousands of lines of code are compressed 
into one line:

```{r do-again}
sample_means50 <- do(2000) * ames %>%
                              sample_n(50, replace = TRUE) %>%
                              summarise(x_bar = mean(area))
```

Note that for each of the 2.000 times we computed a mean, we did so from a 
**different** sample!

1.  To make sure you understand what the `sample_n` and `do` function do, try
    modifying the code to take only **25 sample means** from **samples of size 10**, 
    and put them in a data frame named `sample_means_small`. Print the output. 
    How many elements are there in this object called `sample_means_small`? What does 
    each element represent?

## Sample size and the sampling distribution

Mechanics aside, let's return to the reason we used the `do` function: to compute a 
sampling distribution, specifically, this one.

```{r hist}
qplot(data = sample_means50, x = x_bar)
```

The sampling distribution that we computed tells us much about estimating 
the average living area in homes in Ames.  Because the sample mean is an 
unbiased estimator, the sampling distribution is centered at the true average 
living area of the the population, and the spread of the distribution 
indicates how much variability is induced by sampling only 50 home sales.

In the remainder of this section we will work on getting a sense of the effect that 
sample size has on our sampling distribution

**Step 1:** Create three sampling distributions, each containing 2,000 sample means,
with sample means coming from samples of size $n = 10$, $n = 50$, and $n = 100$.

```{r samp-10-100}
sample_means10 <- do(2000) * ames %>%
                              sample_n(10, replace = TRUE) %>%
                              summarise(x_bar = mean(area))
sample_means50 <- do(2000) * ames %>%
                              sample_n(50, replace = TRUE) %>%
                              summarise(x_bar = mean(area))
sample_means100 <- do(2000) * ames %>%
                              sample_n(100, replace = TRUE) %>%
                              summarise(x_bar = mean(area))
```

**Step 2:** Plot these three sampling distributions on top of each other on the
same scale so that we can easily compare their shapes, centers, and spreads to
each other.

-- **Step 2a:** Combine these three sampling distributions (three $2000 \times 1$ data 
frames) into one $12000 \times 1$ data frame. Note that we're just doing this 
for ease in plotting later. To combine data frames by row, we use the `rbind` function, which stands for **r**ow bind.

```{r samp-dist}
sampling_dist <- rbind(sample_means10, sample_means50, sample_means100)
```

-- **Step 2b:** Add a new column called `sample_size` to the data frame you just
created that indicates the sample size that each case (each sample mean) came
from. Remember the first 2,000 sample means came from samples of size 10, the next
2,000 sample means came from samples of size 50, and the last 2,000 sample means
came from samples of size 100. Hence, this new variable is simply $10$ `rep`eated 
2,000 times, followed by $50$ repeated 2000 times, followed by $100$ repeated 2,000 
times. The use of the `factor` function will ensure that `R` considers this to be a 
categorical variable, and not a numerical one. Also remember that we use the `mutate`
function to create new variables in data frames.

```{r samp-dist-labeled}
sampling_dist <- sampling_dist %>%
  mutate(sample_size = factor(rep(10, 2000), rep(50, 2000), rep(100, 2000)))
```

-- **Step 2c:** Finally, draw three histograms representing these three sampling 
distributions. We can do this via *faceting*, i.e. creating a separate facet in the 
plot for each of the three distributions. Remember that we identify the distributions
with the `sample_size` variable we created earlier, so that's what we use to
create our `facets`. The formula `sample_size ~ .` is new: it splits the y-axis of our
plot into facets by `sample_size` and doesn't split the plot on the x-axis, which
means the plots of the three sampling distributions will be placed on top of each 
other, as opposed to next to each other. We choose this to make it easier to visually 
compare their spreads.

```{r plot-samp-dists}
qplot(data = sampling_dist, x = x_bar, facets = sample_size ~ . )
```

1.  When the sample size is larger, what happens to the center?  What about the 
    spread? Make sure to include the plots in your answer.

* * *

## On your own

So far, we have only focused on estimating the mean living area in homes in 
Ames. Now you'll try to estimate the mean home price.

-   Take a sample of size 15 from the population and calculate the mean `price`
    of the homes in this sample. Using this sample, what is your best point estimate
    of the population mean of prices of homes?

-   Since you have access to the population, simulate the sampling 
    distribution for $\bar{x}_{price}$ by taking 2000 samples from the 
    population of size 15 and computing 2000 sample means. Store these means 
    in a vector called `sample_means15`. Plot the data, then describe the 
    shape of this sampling distribution. Based on this sampling distribution, 
    what would you guess the mean home price of the population to be? Finally, 
    calculate and report the population mean.

-   Change your sample size from 15 to 150, then compute the sampling 
    distribution using the same method as above, and store these means in a 
    new vector called `sample_means150`. Describe the shape of this sampling 
    distribution, and compare it to the sampling distribution for a sample 
    size of 15. Based on this sampling distribution, what would you guess to 
    be the mean sale price of homes in Ames?

-   Of the sampling distributions from 2 and 3, which has a smaller spread?  If
    we're concerned with making estimates that are more often close to the 
    true value, would we prefer a sampling distribution with a large or small spread?

<div id="license">
This is a product of OpenIntro that is released under a [Creative Commons 
Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0).
This lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.
</div>
